import os

from dotenv import load_dotenv
import psycopg2
from psycopg2.extras import DictCursor

from analysis_openai import analyze_article_with_openai

print("ğŸ”¹ [LOG] run_openai_for_articles.py import ì‹œì‘")

# .env ë¡œë“œ
load_dotenv()
print("ğŸ”¹ [LOG] .env ë¡œë“œ ì™„ë£Œ")

# 1) DB ì—°ê²° ìƒì„±
try:
    conn = psycopg2.connect(
        host=os.getenv("DB_HOST", "localhost"),
        port=os.getenv("DB_PORT", "5432"),
        dbname=os.getenv("DB_NAME", "neusis"),
        user=os.getenv("DB_USER", "postgres"),
        password=os.getenv("DB_PASSWORD", "1234"),
    )
    print("ğŸ”¹ [LOG] DB ì—°ê²° ì„±ê³µ")
except Exception as e:
    print("âŒ [ERROR] DB ì—°ê²° ì‹¤íŒ¨:", e)
    raise


def fetch_target_articles(limit: int = 5):
    """
    ì•„ì§ analysis_resultì— ì—†ëŠ” article ëª‡ ê°œ ê°€ì ¸ì˜¤ê¸°.
    """
    print(f"ğŸ”¹ [LOG] fetch_target_articles() í˜¸ì¶œ, limit={limit}")
    with conn.cursor(cursor_factory=DictCursor) as cur:
        cur.execute(
            """
            SELECT a.article_id, a.title, a.content
            FROM article a
            LEFT JOIN analysis_result ar 
                   ON ar.article_id = a.article_id
            WHERE ar.article_id IS NULL
              AND a.content IS NOT NULL
            ORDER BY a.article_id DESC
            LIMIT %s;
            """,
            (limit,),
        )
        rows = cur.fetchall()
        print(f"ğŸ”¹ [LOG] ê°€ì ¸ì˜¨ ê¸°ì‚¬ ê°œìˆ˜: {len(rows)}")
        return rows


def save_analysis_to_db(article_id: int, analysis: dict):
    """
    OpenAI ë¶„ì„ ê²°ê³¼ë¥¼ analysis_result, analysis_keywordsì— ì €ì¥.
    sentimentëŠ” DB ì œì•½ ì¡°ê±´( POSITIVE / NEUTRAL / NEGATIVE / HOPEFUL / ANXIOUS )
    ì— ë§ë„ë¡ ë§¤í•‘í•´ì„œ ë„£ëŠ”ë‹¤.
    """
    print(f"ğŸ”¹ [LOG] save_analysis_to_db() í˜¸ì¶œ, article_id={article_id}")

    summary = (analysis.get("summary") or "").strip()
    sentiment = (analysis.get("sentiment") or "NEUTRAL").strip().upper()
    keywords = analysis.get("keywords") or []

    # âœ… DBê°€ í—ˆìš©í•˜ëŠ” 5ê°€ì§€ ê°’
    allowed = {"POSITIVE", "NEUTRAL", "NEGATIVE", "HOPEFUL", "ANXIOUS"}

    # âœ… GPTê°€ ì¤„ ìˆ˜ ìˆëŠ” ê°ì •ì„ DB ìŠ¤í‚´ì— ë§ê²Œ ë³€í™˜
    mapping = {
        "FEARFUL": "ANXIOUS",
        "FEAR": "ANXIOUS",
        "AFRAID": "ANXIOUS",
        "ANGRY": "NEGATIVE",
        "SAD": "NEGATIVE",
    }

    if sentiment in mapping:
        print(f"ğŸ”¹ [LOG] sentiment ë§¤í•‘: {sentiment} -> {mapping[sentiment]}")
        sentiment = mapping[sentiment]

    if sentiment not in allowed:
        print(f"ğŸ”¹ [LOG] sentiment {sentiment} í—ˆìš©ê°’ ì•„ë‹˜ â†’ NEUTRALë¡œ ë³€ê²½")
        sentiment = "NEUTRAL"

    with conn.cursor() as cur:
        # 1) analysis_result ì¶”ê°€
        cur.execute(
            """
            INSERT INTO analysis_result (
                created_at,
                processed_at,
                sentiment,
                summary,
                trend_score,
                article_id
            )
            VALUES (
                NOW(),
                NOW(),
                %s,
                %s,
                %s,
                %s
            )
            RETURNING result_id;
            """,
            (sentiment, summary, 0.0, article_id),
        )
        result_id = cur.fetchone()[0]
        print(f"ğŸ”¹ [LOG] analysis_result ì €ì¥ ì™„ë£Œ, result_id={result_id}")

        # 2) analysis_keywords ì¶”ê°€
        for kw in keywords:
            kw_str = str(kw).strip()
            if not kw_str:
                continue

            cur.execute(
                """
                INSERT INTO analysis_keywords (result_id, keyword)
                VALUES (%s, %s);
                """,
                (result_id, kw_str),
            )
        print(f"ğŸ”¹ [LOG] analysis_keywords {len(keywords)}ê°œ ì €ì¥ ì™„ë£Œ")

    conn.commit()
    print(f"âœ… [LOG] article_id={article_id} ì „ì²´ ì €ì¥ ì»¤ë°‹ ì™„ë£Œ\n")


def main():
    print("ğŸš€ [LOG] main() ì‹œì‘")

    # 1) ë¶„ì„í•  ê¸°ì‚¬ ê°€ì ¸ì˜¤ê¸°
    articles = fetch_target_articles(limit=5)

    if not articles:
        print("â„¹ï¸ [LOG] ë¶„ì„í•  ëŒ€ìƒ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    for row in articles:
        article_id = row["article_id"]
        title = row["title"]
        content = row["content"] or ""

        print("=" * 80)
        print(f"[article_id={article_id}] {title}")
        print("- ì›ë¬¸ ì¼ë¶€:")
        print(content[:200].strip(), "...\n")

        # 2) OpenAIë¡œ ë¶„ì„
        print("ğŸ”¹ [LOG] OpenAI ë¶„ì„ í˜¸ì¶œ")
        analysis = analyze_article_with_openai(title, content)

        print("ìš”ì•½ :", analysis.get("summary"))
        print("ê°ì • :", analysis.get("sentiment"))
        print("í‚¤ì›Œë“œ :", analysis.get("keywords"))
        print()

        # 3) DB ì €ì¥
        save_analysis_to_db(article_id, analysis)

    conn.close()
    print("ğŸ‰ [LOG] ëª¨ë“  ì‘ì—… ì™„ë£Œ, DB ì—°ê²° ì¢…ë£Œ")


if __name__ == "__main__":
    print("ğŸ”¹ [LOG] __main__ ë¸”ë¡ ì§„ì…")
    main()
